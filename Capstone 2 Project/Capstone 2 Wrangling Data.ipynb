{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volcano_name</th>\n",
       "      <th>eruption_type</th>\n",
       "      <th>VEI</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Soputan</td>\n",
       "      <td>Confirmed Eruption</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.112</td>\n",
       "      <td>124.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>San Miguel</td>\n",
       "      <td>Confirmed Eruption</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.434</td>\n",
       "      <td>-88.269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fournaise, Piton de la</td>\n",
       "      <td>Confirmed Eruption</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21.244</td>\n",
       "      <td>55.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rincon de la Vieja</td>\n",
       "      <td>Confirmed Eruption</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.830</td>\n",
       "      <td>-85.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fernandina</td>\n",
       "      <td>Confirmed Eruption</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.370</td>\n",
       "      <td>-91.550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             volcano_name       eruption_type  VEI     lat      lon\n",
       "0                 Soputan  Confirmed Eruption  NaN   1.112  124.737\n",
       "1              San Miguel  Confirmed Eruption  NaN  13.434  -88.269\n",
       "2  Fournaise, Piton de la  Confirmed Eruption  NaN -21.244   55.708\n",
       "3      Rincon de la Vieja  Confirmed Eruption  NaN  10.830  -85.324\n",
       "4              Fernandina  Confirmed Eruption  NaN  -0.370  -91.550"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bring in each of the data sets and read them into a pandas dataframe, testing each one to make sure it works.\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_excel(r\"C:\\Users\\ryanm\\Desktop\\significant-volcanic-eruption-database.xlsx\")\n",
    "df2 = pd.read_csv(r\"C:\\Users\\ryanm\\Desktop\\volcano.csv\")\n",
    "df3 = pd.read_csv(r\"C:\\Users\\ryanm\\Desktop\\eruptions.csv\")\n",
    "\n",
    "# Print the column names for each data set to see what we will need and what commonalities exist between datasets.\n",
    "df1.columns\n",
    "df_sig = df1[[\"Year\", \"Flag Tsunami\", \"Flag Earthquake\", \"Volcano Name\", \"Country\", \"Elevation\", \"Volcano Type\", \"Volcanic Explosivity Index\"]]\n",
    "df_sig.head()\n",
    "\n",
    "df2.columns\n",
    "df_vol = df2[[\"volcano_name\", \"primary_volcano_type\", \"last_eruption_year\", \"country\", \"latitude\", \"longitude\", \"tectonic_settings\", \"major_rock_1\"]]\n",
    "df_vol.head()\n",
    "\n",
    "df3.columns\n",
    "df_erupt = df3[[\"volcano_name\", \"eruption_category\", \"vei\", \"latitude\", \"longitude\"]]\n",
    "df_erupt.head()\n",
    "\n",
    "# Rename columns as necessary to make them easier to work with and make similar/same as others in the datasets.\n",
    "df_sig = df_sig.rename(columns={\"Year\" : \"year\", \"Flag Tsunami\" : \"tsunami\", \"Flag Earthquake\" : \"earthquake\", \"Volcano Name\" : \"volcano_name\", \"Country\" : \"country\", \"Elevation\" : \"elevation\", \"Volcano Type\" : \"volcano_type\", \"Volcanic Explosivity Index\" : \"VEI\"})\n",
    "df_vol = df_vol.rename(columns={\"primary_volcano_type\" : \"volcano_type\", \"last_eruption_year\" : \"year\", \"latitude\" : \"lat\", \"longitude\" : \"lon\", \"tectonic_settings\" : \"tectonic_setting\", \"major_rock_1\" : \"rock_type\"})\n",
    "df_erupt = df_erupt.rename(columns={\"eruption_category\" : \"eruption_type\", \"vei\" : \"VEI\", \"latitude\" : \"lat\", \"longitude\" : \"lon\"})\n",
    "\n",
    "# Check new .head() to make sure the changes were made.\n",
    "df_sig.head()\n",
    "df_vol.head()\n",
    "df_erupt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volcano_name</th>\n",
       "      <th>eruption_type</th>\n",
       "      <th>VEI</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abu</td>\n",
       "      <td>Confirmed Eruption</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.500</td>\n",
       "      <td>131.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acatenango</td>\n",
       "      <td>Confirmed Eruption</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.501</td>\n",
       "      <td>-90.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acatenango</td>\n",
       "      <td>Confirmed Eruption</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.501</td>\n",
       "      <td>-90.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acatenango</td>\n",
       "      <td>Confirmed Eruption</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.501</td>\n",
       "      <td>-90.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Acatenango</td>\n",
       "      <td>Confirmed Eruption</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.501</td>\n",
       "      <td>-90.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Acatenango</td>\n",
       "      <td>Confirmed Eruption</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.501</td>\n",
       "      <td>-90.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Acatenango</td>\n",
       "      <td>Confirmed Eruption</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.501</td>\n",
       "      <td>-90.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Acatenango</td>\n",
       "      <td>Confirmed Eruption</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.501</td>\n",
       "      <td>-90.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Acatenango</td>\n",
       "      <td>Confirmed Eruption</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.501</td>\n",
       "      <td>-90.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Acigol-Nevsehir</td>\n",
       "      <td>Confirmed Eruption</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.537</td>\n",
       "      <td>34.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Acigol-Nevsehir</td>\n",
       "      <td>Confirmed Eruption</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.537</td>\n",
       "      <td>34.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Acigol-Nevsehir</td>\n",
       "      <td>Confirmed Eruption</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.537</td>\n",
       "      <td>34.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Acigol-Nevsehir</td>\n",
       "      <td>Confirmed Eruption</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.537</td>\n",
       "      <td>34.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Acigol-Nevsehir</td>\n",
       "      <td>Confirmed Eruption</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.537</td>\n",
       "      <td>34.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Adams</td>\n",
       "      <td>Confirmed Eruption</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46.206</td>\n",
       "      <td>-121.490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       volcano_name       eruption_type  VEI     lat      lon\n",
       "1               Abu  Confirmed Eruption  NaN  34.500  131.600\n",
       "2        Acatenango  Confirmed Eruption  NaN  14.501  -90.876\n",
       "3        Acatenango  Confirmed Eruption  3.0  14.501  -90.876\n",
       "4        Acatenango  Confirmed Eruption  2.0  14.501  -90.876\n",
       "5        Acatenango  Confirmed Eruption  NaN  14.501  -90.876\n",
       "6        Acatenango  Confirmed Eruption  1.0  14.501  -90.876\n",
       "7        Acatenango  Confirmed Eruption  NaN  14.501  -90.876\n",
       "8        Acatenango  Confirmed Eruption  NaN  14.501  -90.876\n",
       "9        Acatenango  Confirmed Eruption  NaN  14.501  -90.876\n",
       "10  Acigol-Nevsehir  Confirmed Eruption  NaN  38.537   34.621\n",
       "11  Acigol-Nevsehir  Confirmed Eruption  NaN  38.537   34.621\n",
       "12  Acigol-Nevsehir  Confirmed Eruption  NaN  38.537   34.621\n",
       "13  Acigol-Nevsehir  Confirmed Eruption  NaN  38.537   34.621\n",
       "14  Acigol-Nevsehir  Confirmed Eruption  NaN  38.537   34.621\n",
       "15            Adams  Confirmed Eruption  2.0  46.206 -121.490"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set + Reset the index for volcano_name for each dataset and view, sorting volcano_name alphabetically.\n",
    "df_sig.head()\n",
    "#print(df_sig.index) to confirm index is set to volcano_name\n",
    "df_sig_ind = df_sig.set_index(\"volcano_name\").sort_index()\n",
    "df_sig_ind.reset_index(inplace=True)\n",
    "df_sig_ind.index += 1\n",
    "df_sig_ind.head(15)\n",
    "\n",
    "#Repeat for other datasets\n",
    "df_vol.head()\n",
    "df_vol_ind = df_vol.set_index(\"volcano_name\").sort_index()\n",
    "df_vol_ind.reset_index(inplace=True)\n",
    "df_vol_ind.index += 1\n",
    "df_vol_ind.head(15)\n",
    "\n",
    "df_erupt.head()\n",
    "df_erupt_ind = df_erupt.set_index(\"volcano_name\").sort_index()\n",
    "df_erupt_ind.reset_index(inplace=True)\n",
    "df_erupt_ind.index += 1\n",
    "df_erupt_ind.head(15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 835 entries, 1 to 835\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   volcano_name  835 non-null    object \n",
      " 1   year          835 non-null    int64  \n",
      " 2   tsunami       145 non-null    object \n",
      " 3   earthquake    67 non-null     object \n",
      " 4   country       835 non-null    object \n",
      " 5   elevation     835 non-null    int64  \n",
      " 6   volcano_type  835 non-null    object \n",
      " 7   VEI           659 non-null    float64\n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 52.3+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 958 entries, 1 to 958\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   volcano_name      958 non-null    object \n",
      " 1   volcano_type      958 non-null    object \n",
      " 2   year              958 non-null    object \n",
      " 3   country           958 non-null    object \n",
      " 4   lat               958 non-null    float64\n",
      " 5   lon               958 non-null    float64\n",
      " 6   tectonic_setting  958 non-null    object \n",
      " 7   rock_type         958 non-null    object \n",
      "dtypes: float64(2), object(6)\n",
      "memory usage: 60.0+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11178 entries, 1 to 11178\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   volcano_name   11178 non-null  object \n",
      " 1   eruption_type  11178 non-null  object \n",
      " 2   VEI            8272 non-null   float64\n",
      " 3   lat            11178 non-null  float64\n",
      " 4   lon            11178 non-null  float64\n",
      "dtypes: float64(3), object(2)\n",
      "memory usage: 436.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Starting with our volcano_name column, let's count the unique and total values for each dataset.\n",
    "df_sig_ind[\"volcano_name\"].value_counts()\n",
    "df_sig_ind[\"volcano_name\"].count()\n",
    "# 267 unique values, 835 total values\n",
    "df_vol_ind[\"volcano_name\"].value_counts()\n",
    "df_vol_ind[\"volcano_name\"].count()\n",
    "# 954 unique values, 958 total values\n",
    "df_erupt_ind[\"volcano_name\"].value_counts()\n",
    "df_erupt_ind[\"volcano_name\"].count()\n",
    "# 921 unique values, 11178 total values\n",
    "\n",
    "# Let's take a quick look at info for each dataset to see what we're working with.\n",
    "df_sig_ind.info()\n",
    "df_vol_ind.info()\n",
    "df_erupt_ind.info()\n",
    "\n",
    "# So the df_erupt_ind dataset has a lot of null values for VEI, which is a problem. Let's see how many null values there are.\n",
    "df_erupt_ind.isnull().sum()\n",
    "# Since VEI is a very important column for our analysis, we need to drop the rows with null values.\n",
    "df_erupt_ind.dropna(subset=[\"VEI\"], inplace=True)\n",
    "df_erupt_ind.isnull().sum()\n",
    "# Looks good, down to 8272 rows from 11178 and all rows have a value for VEI. Let's do the same for the other datasets.\n",
    "df_sig_ind.dropna(subset=[\"VEI\"], inplace=True)\n",
    "df_sig_ind.isnull().sum()\n",
    "# We have a lot of null(they are blank in the sheet) values for tsunami and earthquake, however these variables aren't as imperative\n",
    "# for our analysis so we can leave them as is for now.  Let's see if the data that currently exists can provide some insight when we analyze it.\n",
    "df_vol_ind.isnull().sum()\n",
    "# This dataset doesn't include the VEI column, and shows no null values in its data.  We will eventually need to merge this dataset\n",
    "# with the df_erupt_ind dataset to get the VEI column from matching data and then drop the null values from that dataset.\n",
    "# But first let's address any data inconsistencies so it makes our pending merge easier.\n",
    "\n",
    "\n",
    "# Let's start with the df_sig_ind dataset.\n",
    "df_sig_ind.head()\n",
    "df_sig_ind[\"volcano_type\"].unique()\n",
    "#There's two types of submarine volcanoes, so let's combine them into one.\n",
    "df_sig_ind[\"volcano_type\"].replace({\"Submarine volcanoes\" : \"Submarine volcano\"}, inplace=True)\n",
    "# Let's check to see if it worked.\n",
    "df_sig_ind[\"volcano_type\"].unique()\n",
    "# Let's check out our primary VEI column for those scores.\n",
    "df_sig_ind[\"VEI\"].value_counts()\n",
    "df_sig_ind.drop(df_sig_ind[df_sig_ind[\"VEI\"] == 0.0].index, inplace=True)\n",
    "# Great, now on to the others.\n",
    "\n",
    "\n",
    "df_vol_ind.head(25)\n",
    "# Looks like we have 3 columns to work on here, volcano_type, tectonic_setting, and rock_type.\n",
    "df_vol_ind[\"volcano_type\"].unique()\n",
    "#There's a few we need to edit here, let's get rid of some of those suffixes.\n",
    "df_vol_ind[\"volcano_type\"] = df_vol_ind[\"volcano_type\"].apply(lambda x: x.replace(\"(s)\", \"\").replace(\"(es)\", \"\"))\n",
    "df_vol_ind[\"volcano_type\"].unique()\n",
    "df_vol_ind[\"volcano_type\"].value_counts()\n",
    "# Looks good, let's do the other ones.\n",
    "df_vol_ind[\"tectonic_setting\"].value_counts()\n",
    "# Hmm what is that Unknown tectonic setting? Let's see if we can find out.\n",
    "df_vol_ind[df_vol_ind[\"tectonic_setting\"] == \"Unknown\"]\n",
    "# Without a year as well, we can't really do anything with this data. Let's drop it.\n",
    "df_vol_ind.drop(df_vol_ind[df_vol_ind[\"tectonic_setting\"] == \"Unknown\"].index, inplace=True)\n",
    "# Let's check to make sure it worked.\n",
    "df_vol_ind[\"tectonic_setting\"].value_counts()\n",
    "# Now let's look at the data format.\n",
    "df_vol_ind[\"tectonic_setting\"].unique()\n",
    "# We are not as concerned with the crust suffixes in this project, let's remove the long suffixes and combine the settings to make it easy on us here.\n",
    "df_vol_ind[\"tectonic_setting\"] = df_vol_ind[\"tectonic_setting\"].apply(lambda x: x.replace(\" / Continental crust (>25 km)\", \"\").replace(\" / Continental crust (>25 km)\", \"\").replace(\" / Intermediate crust (15-25 km)\", \"\").replace(\" / Crustal thickness unknown\", \"\").replace(\" / Oceanic crust (< 15 km)\", \"\").replace(\" / Oceanic crust (< 15 km)\", \"\").replace(\" / Intermediate crust (15-25 km)\", \"\").replace(\" / Continental crust (>25 km)\", \"\").replace(\" / Oceanic crust (< 15 km)\", \"\").replace(\" / Intermediate crust (15-25 km)\", \"\"))\n",
    "df_vol_ind[\"tectonic_setting\"].unique()\n",
    "# Looks good, let's do the last one for this dataset.\n",
    "df_vol_ind[\"rock_type\"].unique()\n",
    "# This column is similar to the tectonic_setting column in its format inconsistencies, let's write another lambda function to clean it up.\n",
    "df_vol_ind[\"rock_type\"] = df_vol_ind[\"rock_type\"].apply(lambda x: x.replace(\" / Basaltic Andesite\", \"\").replace(\" / Picro-Basalt\", \"\").replace(\" / Trachydacite\", \"\").replace(\" /  Tephri-phonolite\", \"\").replace(\" / Basaltic Trachyandesite\", \"\").replace(\" / Tephrite Basanite\", \"\"))\n",
    "df_vol_ind[\"rock_type\"].unique()\n",
    "# Let's check out a quick .head() to make sure everything looks good.\n",
    "df_vol_ind.head(25)\n",
    "# We probably shouldn't have Unknown years in our dataset, let's see how many there are.\n",
    "df_vol_ind[\"year\"].value_counts()\n",
    "# Even though there's quite a few let's drop them because we need the year for our analysis.\n",
    "df_vol_ind.drop(df_vol_ind[df_vol_ind[\"year\"] == \"Unknown\"].index, inplace=True)\n",
    "df_vol_ind.head(25)\n",
    "\n",
    "\n",
    "df_erupt_ind[\"eruption_type\"].unique()\n",
    "# Uncertain Eruption doesn't sound good for our data, if it didn't happen we don't want it in our dataset.\n",
    "df_erupt_ind[\"eruption_type\"].value_counts()\n",
    "# Again quite a few but let's drop them as they are not useful for our analysis.\n",
    "df_erupt_ind.drop(df_erupt_ind[df_erupt_ind[\"eruption_type\"] == \"Uncertain Eruption\"].index, inplace=True)\n",
    "# Now that the column has been normalized with its data, let's go ahead and drop the column as we don't need it anymore.\n",
    "df_erupt_ind.drop(columns=[\"eruption_type\"], inplace=True)\n",
    "df_erupt_ind.head(25)\n",
    "df_erupt_ind[\"VEI\"].value_counts()\n",
    "# Let's drop the Unknown VEI values showing a score of 0.0 as they are not useful for our analysis.\n",
    "df_erupt_ind.drop(df_erupt_ind[df_erupt_ind[\"VEI\"] == 0.0].index, inplace=True)\n",
    "df_erupt_ind[\"VEI\"].value_counts()\n",
    "df_erupt_ind.head(25)\n",
    "# After deliberating about it, let's drop the tsunami and earthquake columns from the df_sig_ind dataset.  There is just not enough information to make them useful for our analysis.\n",
    "df_sig_ind.drop(columns=[\"tsunami\", \"earthquake\"], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Everything looks good, let's move on to merging the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2599"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before we start merging, let's check the datatypes of each dataset to make sure they are compatible for merging.\n",
    "df_vol_ind.dtypes\n",
    "df_sig_ind.dtypes\n",
    "df_erupt_ind.dtypes\n",
    "# To make reading and processing some of these categories later, let's change the datatypes of the volcano_type(s), tectonic_setting, rock_type, and year columns to categorical data.\n",
    "# Also as a good measure change both VEI columns to int64 datatypes.\n",
    "df_vol_ind[\"volcano_type\"] = df_vol_ind[\"volcano_type\"].astype(\"category\")\n",
    "df_vol_ind[\"tectonic_setting\"] = df_vol_ind[\"tectonic_setting\"].astype(\"category\")\n",
    "df_vol_ind[\"rock_type\"] = df_vol_ind[\"rock_type\"].astype(\"category\")\n",
    "df_sig_ind[\"volcano_type\"] = df_sig_ind[\"volcano_type\"].astype(\"category\")\n",
    "df_sig_ind[\"VEI\"] = df_sig_ind[\"VEI\"].astype(\"int64\")\n",
    "df_erupt_ind[\"VEI\"] = df_erupt_ind[\"VEI\"].astype(\"int64\")\n",
    "df_vol_ind[\"year\"] = df_vol_ind[\"year\"].astype(\"int64\")\n",
    "df_sig_ind[\"year\"] = df_sig_ind[\"year\"].astype(\"int64\")\n",
    "# Check dtypes for each dataset to make sure the changes were made.\n",
    "df_vol_ind.dtypes\n",
    "df_sig_ind.dtypes\n",
    "df_erupt_ind.dtypes\n",
    "# The df_erupt_ind has a lot of duplicate rows, let's drop them to make our merge easier.  We will keep the first instance of each duplicate row.\n",
    "df_erupt_ind.drop_duplicates(keep=\"first\", inplace=True)\n",
    "# Let's also drop duplicates from the df_sig_ind dataset, as we don't want to merge duplicate rows.\n",
    "df_sig_ind.drop_duplicates(keep=\"first\", inplace=True)\n",
    "# Let's also while we are at it remove whitespaces from the volcano_name column in each dataset.\n",
    "df_vol_ind.head(25)\n",
    "df_vol_ind['volcano_name'] = df_vol_ind['volcano_name'].str.strip()\n",
    "df_vol_ind.index += 1\n",
    "df_vol_ind.head(25)\n",
    "# Now for the others, checking for other potential errors as we go.\n",
    "df_sig_ind.head(25)\n",
    "df_sig_ind['volcano_name'] = df_sig_ind['volcano_name'].str.strip()\n",
    "df_sig_ind.index += 1\n",
    "df_sig_ind.head(25)\n",
    "# We will reset the index(es) after the merge is complete, so not worried at this time about the gaps in the index.\n",
    "df_erupt_ind.head()\n",
    "# As an aside task we will drop matching duplicated rows from this dataset, to make our forthcoming merge easier.\n",
    "df_erupt_ind.drop_duplicates(keep=\"first\", inplace=True)\n",
    "df_erupt_ind.head()\n",
    "df_erupt_ind['volcano_name'] = df_erupt_ind['volcano_name'].str.strip()\n",
    "df_erupt_ind.index += 1\n",
    "df_erupt_ind.head()\n",
    "\n",
    "# Let's start with the df_vol_ind dataset and merge it with the df_sig_ind dataset.\n",
    "df_volsig_pre = pd.merge(df_vol_ind, df_sig_ind, on=[\"volcano_name\", \"volcano_type\", \"year\", \"country\"], how=\"outer\")\n",
    "df_volsig_pre.head(25)\n",
    "df_volsig_pre.count()\n",
    "# Looks good, our min count value is 614. Let's bring in the df_erupt_ind dataset and merge it with the df_volsig_pre dataset to get some more.\n",
    "df_volsigeru_pre = pd.merge(df_volsig_pre, df_erupt_ind, on=[\"volcano_name\", \"lat\", \"lon\", \"VEI\"], how=\"outer\")\n",
    "df_volsigeru_pre.head(25)\n",
    "df_volsigeru_pre.count()\n",
    "# Both datasets are now merged, let's reset the index and check for any null values.\n",
    "df_volsigeru_pre.reset_index(inplace=True)\n",
    "df_volsigeru_pre.index += 1\n",
    "df_volsigeru_pre.head(25)\n",
    "df_volsigeru_pre = df_volsigeru_pre.drop(columns=[\"index\"])\n",
    "df_volsigeru_pre.head(25)\n",
    "\n",
    "# Thinking ahead, let's add dummy variables for the categorical data in our dataset and make sure the data types are int64.\n",
    "dummy_df = pd.get_dummies(df_volsigeru_pre[[\"volcano_type\", \"tectonic_setting\", \"rock_type\"]], dummy_na=False, dtype=\"int64\")\n",
    "df_volsigeru_pre = pd.concat([df_volsigeru_pre, dummy_df], axis=1)\n",
    "\n",
    "\n",
    "df_volsigeru_pre.head(25)\n",
    "# Let's check for null values.\n",
    "#df_volsigeru_pre.count()\n",
    "#df_volsigeru_pre.isnull().sum()\n",
    "# There is a decision to make here.  We have a lot of null values in our merged dataset, but we also have a lot of data.  We can drop the null values and lose a lot of data, or we can keep the null values and work with what we have.  I think we should keep the null values and work with what we have, as we have a lot of data to work with.\n",
    "# Let's work on paring down the null values and making our dataset easier to work with.\n",
    "df_volsigeru_pre[\"volcano_name\"].drop_duplicates()\n",
    "df_volsigeru_pre[\"volcano_name\"].count()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
